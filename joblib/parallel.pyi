from typing import Any, Callable, Dict, Generator, List, Optional, Tuple, TypeVar

from ._multiprocessing_helpers import mp as mp
from ._parallel_backends import AutoBatchingMixin as AutoBatchingMixin
from ._parallel_backends import FallbackToBackend as FallbackToBackend
from ._parallel_backends import LokyBackend as LokyBackend
from ._parallel_backends import MultiprocessingBackend as MultiprocessingBackend
from ._parallel_backends import ParallelBackendBase as ParallelBackendBase
from ._parallel_backends import SequentialBackend as SequentialBackend
from ._parallel_backends import ThreadingBackend as ThreadingBackend
from .disk import memstr_to_bytes as memstr_to_bytes
from .externals import loky as loky
from .externals.cloudpickle import dumps as dumps
from .externals.cloudpickle import loads as loads
from .logger import Logger as Logger
from .logger import short_format_time as short_format_time

delayedFunctionReturnType = TypeVar("delayedFunctionReturnType")

BACKENDS: Any
DEFAULT_BACKEND: str
DEFAULT_N_JOBS: int
DEFAULT_THREAD_BACKEND: str
VALID_BACKEND_HINTS: Any
VALID_BACKEND_CONSTRAINTS: Any
EXTERNAL_BACKENDS: Any

def get_active_backend(
    prefer: Optional[Any] = ..., require: Optional[Any] = ..., verbose: int = ...
): ...

class parallel_backend:
    old_backend_and_jobs: Any = ...
    new_backend_and_jobs: Any = ...
    def __init__(
        self,
        backend: Any,
        n_jobs: int = ...,
        inner_max_num_threads: Optional[Any] = ...,
        **backend_params: Any
    ) -> None: ...
    def __enter__(self): ...
    def __exit__(self, type: Any, value: Any, traceback: Any) -> None: ...
    def unregister(self) -> None: ...

DEFAULT_MP_CONTEXT: Any
method: Any

class BatchedCalls:
    items: Any = ...
    def __init__(
        self,
        iterator_slice: Any,
        backend_and_jobs: Any,
        reducer_callback: Optional[Any] = ...,
        pickle_cache: Optional[Any] = ...,
    ) -> None: ...
    def __call__(self): ...
    def __reduce__(self): ...
    def __len__(self): ...

def cpu_count(only_physical_cores: bool = ...): ...

# def delayed(function: Any): ...
def delayed(
    whattododelayed: Callable[..., delayedFunctionReturnType]
) -> Callable[
    ..., Tuple[Callable[..., delayedFunctionReturnType], Tuple, Dict[str, Any]]
]: ...

class BatchCompletionCallBack:
    dispatch_timestamp: Any = ...
    batch_size: Any = ...
    parallel: Any = ...
    def __init__(
        self, dispatch_timestamp: Any, batch_size: Any, parallel: Any
    ) -> None: ...
    def __call__(self, out: Any) -> None: ...

def register_parallel_backend(
    name: Any, factory: Any, make_default: bool = ...
) -> None: ...
def effective_n_jobs(n_jobs: int = ...): ...

class Parallel(Logger):
    n_jobs: Any = ...
    verbose: Any = ...
    timeout: Any = ...
    pre_dispatch: Any = ...
    batch_size: Any = ...
    def __init__(
        self,
        n_jobs: Optional[Any] = ...,
        backend: Optional[Any] = ...,
        verbose: int = ...,
        timeout: Optional[Any] = ...,
        pre_dispatch: str = ...,
        batch_size: str = ...,
        temp_folder: Optional[Any] = ...,
        max_nbytes: str = ...,
        mmap_mode: str = ...,
        prefer: Optional[Any] = ...,
        require: Optional[Any] = ...,
    ) -> None: ...
    def __enter__(self): ...
    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None: ...
    def dispatch_next(self) -> None: ...
    def dispatch_one_batch(self, iterator: Any): ...
    def print_progress(self) -> None: ...
    def retrieve(self) -> None: ...
    n_dispatched_batches: int = ...
    n_dispatched_tasks: int = ...
    n_completed_tasks: int = ...
    #    def __call__(self, iterable: Any): ...
    def __call__(
        self,
        iterable: Generator[
            Tuple[Callable[..., delayedFunctionReturnType], Tuple, Dict[str, Any]],
            None,
            None,
        ],
    ) -> List[delayedFunctionReturnType]: ...
